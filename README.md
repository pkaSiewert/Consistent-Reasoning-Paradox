# Consistent-Reasoning-Paradox
We share the prompts we tested to illustrate the theoretical results of the preprint "Necessary Mechanisms for super AI and stopping hallucinations".

It is perhaps unsurprising that both ChatGPT 5 Thinking and DeepSeek R1 are able to correctly answer prompts 4a, 4b, 4c, and 5a (though they do make mistakes sometimes). We record this in the directory Successes.

The prompts 5b, 5c, and 5d were tested 15 times each on ChatGPT 5 Thinking and 10 times each on DeepSeek R1. The number of correct responses are recorded in the following table.

| Prompt | ChatGPT 5 Thinking | DeepSeek R1 |
|:------:|:------------------:|:-----------:|
| 5b     | 4                  |  3          |
| 5c     | 2                  |   0         |
| 5d     | 4                  |  5          |

Thus it is clear that neither model is able to consistently answer these prompts correctly.
