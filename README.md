# Consistent-Reasoning-Paradox
We share the prompts we tested to illustrate the theoretical results of the preprint "Necessary mechanisms for super AI and stopping hallucinations: The consistent reasoning paradox and the indeterminacy function".

Figures 4 and 5 of the main paper report the behaviour of ChatGPT 5 Thinking and DeepSeek R1 on a selection of prompts we designed. Figure 4 has the prompts 4a, 4b, and 4c, and Figure 5 has the prompts 5a, 5b, 5c, and 5d. 

It is perhaps unsurprising that both ChatGPT 5 Thinking and DeepSeek R1 are able to correctly answer prompts 4a, 4b, 4c, and 5a (though they do make mistakes sometimes). We record this in the directory Successes.

The prompts 5b, 5c, and 5d were tested 15 times each on ChatGPT 5 Thinking and 10 times each on DeepSeek R1. The number of correct responses are recorded in the following table.

| Prompt | ChatGPT 5 Thinking <br> correct out of 15 | DeepSeek R1 <br> correct out of 10|
|:------:|:------------------:|:-----------:|
| 5b     | 4                  |  3          |
| 5c     | 2                  |   0         |
| 5d     | 4                  |  5          |

Thus it is clear that neither model is able to consistently answer any of these prompts correctly.
